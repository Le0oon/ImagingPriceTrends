{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, datasets\n",
    "import torch\n",
    "from torch import nn\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "sys.path.append('../codes/')\n",
    "from network import CNN_with_decoder,CNN2,Decoder\n",
    "from losses import  loss\n",
    "from optimizer import create_optimizer\n",
    "from data import ImageData\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp=open('../logs/output.log','a+')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN2().to(device)\n",
    "# 定义代价函数\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageData('../data_base_500/train')\n",
    "train_set, val_set = train_test_split(dataset, test_size=0.3, random_state=42)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "demo_model = CNN_with_decoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model weights\n",
    "pretrained_dict  = torch.load('../models/Finance_cnn2_lr1e-05_adam_wd0.0001_epoch30_model.pth')\n",
    "\n",
    "my_model = Decoder()\n",
    "new_model_dict = my_model.state_dict()\n",
    "for key in pretrained_dict:\n",
    "    if key in new_model_dict:\n",
    "        new_model_dict[key] = pretrained_dict[key]\n",
    "my_model.load_state_dict(new_model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 冻结CNN部分\n",
    "for param in my_model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in my_model.decoder.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load loss function\n",
    "from losses import CustomLoss\n",
    "from engine import train_decoder_model\n",
    "optimizer = torch.optim.Adam(my_model.decoder.parameters(), lr=0.001)\n",
    "loss = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Epoch [1/10] - Train Loss: 3.1398 - Val Loss: 24.6036\n",
      "Val R square: 0: 0.9181, 1: 0.8711, 2: 0.8034\n",
      "Epoch [2/10] - Train Loss: 3.1181 - Val Loss: 27.7167\n",
      "Val R square: 0: 0.9112, 1: 0.8647, 2: 0.7680\n",
      "Epoch [3/10] - Train Loss: 2.8681 - Val Loss: 25.1781\n",
      "Val R square: 0: 0.9176, 1: 0.8463, 2: 0.8069\n",
      "Epoch [4/10] - Train Loss: 2.3175 - Val Loss: 25.8073\n",
      "Val R square: 0: 0.9157, 1: 0.8636, 2: 0.7915\n",
      "Epoch [5/10] - Train Loss: 3.2135 - Val Loss: 24.3413\n",
      "Val R square: 0: 0.9181, 1: 0.8781, 2: 0.8043\n",
      "Epoch [6/10] - Train Loss: 1.6700 - Val Loss: 25.3223\n",
      "Val R square: 0: 0.9166, 1: 0.8581, 2: 0.8005\n",
      "Epoch [7/10] - Train Loss: 2.6898 - Val Loss: 28.2150\n",
      "Val R square: 0: 0.9102, 1: 0.8719, 2: 0.7580\n",
      "Epoch [8/10] - Train Loss: 3.0910 - Val Loss: 24.3203\n",
      "Val R square: 0: 0.9177, 1: 0.8782, 2: 0.8053\n",
      "Epoch [9/10] - Train Loss: 1.7176 - Val Loss: 25.1125\n",
      "Val R square: 0: 0.9174, 1: 0.8711, 2: 0.7964\n",
      "Epoch [10/10] - Train Loss: 2.7043 - Val Loss: 27.1145\n",
      "Val R square: 0: 0.9094, 1: 0.8513, 2: 0.7873\n"
     ]
    }
   ],
   "source": [
    "\n",
    "my_model.to(device)\n",
    "model = train_decoder_model(my_model, train_loader, val_loader,\n",
    "                            optimizer,10,loss,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.to(device)\n",
    "predict_data = [[] for _ in range(3)]\n",
    "origin_data = [[] for _ in range(3)]\n",
    "with torch.no_grad():\n",
    "    for inputs, _, attr in val_loader:\n",
    "        inputs, attr = inputs.to(device), attr.to(device)\n",
    "        outputs = my_model(inputs)\n",
    "        for i in range(3):\n",
    "            predict_data[i].extend(list(outputs[:, i].cpu().numpy()))\n",
    "            origin_data[i].extend(list(attr[:, i].cpu().numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1436498.730761146"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(predict_data[0],origin_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Self-supervised Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
